# マニュアルの補足  
マニュアル.mdはChatGPTに作ってもらったドキュメントです。  
なので補足的文章はこっちに追記していきます。  

## データの前処理（正規化）  
```python
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])
```
ここでは画像データの前処理として各種変換を定義しているようです。  
```python
transforms.ToTensor()
```
これは画像データをテンソルに変換します。
さらに値を0~1に変換するようです。
```python
transforms.Normalize((0.5,), (0.5,))
```
これは平均(0.5,)、標準偏差(0.5,)に正規化します。(-1~1に変換)  
今回はグレースケールなので1チャンネルになっています。RGB形式なら(0.5,0.5,0.5)のようにします。(0.5,)とカンマを残しているのはタプル形式であることを明示しているようです。  
  
## 訓練データとテストデータをダウンロード  
```python
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)

testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)
```
MNISTは0~9の28x28グレースケールの手書き画像データです。よく使われます。  
他にもデータセットがいろいろ存在するので書き換えて遊んでみてください。  
ちなみに深層学習には訓練データというモデルの学習用のデータとテストデータというモデルの評価用のデータがあります。  
僕たちの目的は与えたデータに完璧に答えるモデルを作ることではなく、未知のデータに対しても高い性能を発揮するモデルです。(汎化能力の高いモデル)  
ですので性能を測るデータは学習に用いたデータとは別のデータで測る必要がありtrain_dataとtest_dataがあります。  
```python
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True,transform=transform)
```  
rootはデータの保存先のルートディレクトリを指定できます。  
trainはTrueで訓練データが、Falseでテストデータを取得できます。(それぞれデータとか枚数とかが違う)  
downloadはデータがローカルでrootの指定場所に無い場合にダウンロードするかしないかを指定。  
transformは定義した前処理を渡す。  

```python
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)
```
訓練データを渡すDataLoaderの定義をする。  
trainsetは前の訓練データの集合を渡す。  
batch_sizeではミニバッチ学習をするときのミニバッチ数を指定。  
shuffleは学習ごとにデータをシャッフルするかどうかを指定。  

## ニューラルネットワークの定義  
```python
class SimpleNN(nn.Module):
    def __init__(self):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(28 * 28, 128)  # 入力層（28x28ピクセル） → 隠れ層（128ユニット）
        self.fc2 = nn.Linear(128, 10)  # 隠れ層 → 出力層（10クラス：0~9）

    def forward(self, x):
        x = x.view(-1, 28 * 28)  # 画像を1次元のベクトルに変換
        x = torch.relu(self.fc1(x))  # 活性化関数ReLU適用
        x = self.fc2(x)  # 出力計算（Softmax適用は損失関数側で処理）
        return x
```  
ニューラルネットワークをクラスで定義しています。
```python
class SimpleNN(nn.Module):
```
クラスで定義する際、nn.Moduleから継承する形で行っています。  
ニューラルネットワークとして共通の機能はライブラリで定義されていて初期化と計算のユーザーはカスタマイズ出来るようになっています。うれしいね。  
```python
def __init__(self):
    super(SimpleNN, self).__init__()
    self.fc1 = nn.Linear(28 * 28, 128)  # 入力層（28x28ピクセル） → 隠れ層（128ユニット）
    self.fc2 = nn.Linear(128, 10)  # 隠れ層 → 出力層（10クラス：0~9）
```
ネットワークの初期化を行い、モデルの設計をここで行います。
```python
super(SimpleNN, self).__init__()
```
は親クラスの初期化関数を呼び出しています。クラスを継承する時はこの記述が必須です。  
```python
self.fc1 = nn.Linear(28 * 28, 128)  # 入力層（28x28ピクセル） → 隠れ層（128ユニット）
self.fc2 = nn.Linear(128, 10)  # 隠れ層 → 出力層（10クラス：0~9）
```
ここでニューラルネットワークの層の設計をしています。  
コメントから読み取れるように三層ネットワークになっていて入力は画像の画素784ユニットの入力から隠れ層128ユニットへ  
そして隠れ層128ユニットから出力層10ユニットの全結合ネットワークになっています。  
この10ユニットに0~9の予測値が計算され一番高いラベル(0~9)がその画像の判定結果となります。  
内部的にはsoftmaxによって0~9の確率分布が計算されるがoutputsにはそれを計算する前の段階の値であるlogitsというスコアが格納される。それでもこの中で大小関係は変わらないのでスコアの最も高いラベルを予測値として返す。  
```python
def forward(self, x):
    x = x.view(-1, 28 * 28)  # 画像を1次元のベクトルに変換
    x = torch.relu(self.fc1(x))  # 活性化関数ReLU適用
    x = self.fc2(x)  # 出力計算（Softmax適用は損失関数側で処理）
    return x
```
forwardではニューラルネットワークの順伝播の計算を定義する。基本的にコメントにある通りの意味。  
```python
self.fc1(x)
```
で全結合による線形変換を行う。fc2も同様。  
```python
torch.relu(~)
```
これで活性化関数を適用している。ここで採用される関数は全て非線形で複雑な表現を期待している。  
中でも今回のReLU関数がよく使われ入力が正で入力をそのまま返し、負で0を返すような割と単純な形をしている。  
出力を確率分布的にするにはsoftmax関数が使われるのだが今回は誤差関数にCrossEntropyLossを用いており、この内部で同等の計算をするためにここでは定義されない。あまり気にしなくてもいい  

## モデルの学習
```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = SimpleNN().to(device)  # GPUが利用可能ならGPUへ転送
```
GPU(CUDA)がもし使えるなら使ってくれるという処理をしています。  
GPUによる処理に対応しているライブラリなのですごく楽です。  
もし使えなくてもこのコードでCPUに切り替えてくれるので気にせず実行して大丈夫です。  

```python
criterion = nn.CrossEntropyLoss()  # 損失関数（クロスエントロピー）
```
ここで誤差関数を定義しています。クロスエントロピー(交差エントロピー)誤差と呼ばれるもので値そのものの誤差を測る二乗誤差とは違い、こちらは確率分布の間の誤差を測ってくれます。  
もし値の予測(回帰問題)をしたいなら二乗誤差、ラベルの予測(分類問題)をしたいならクロスエントロピー誤差を使いましょう。  
```python
optimizer = optim.Adam(model.parameters(), lr=0.001)  # 最適化手法（Adam）
```
ここでモデルの最適化手法を定義しています。このAdamってやつが人気でよく使われます。  
AIモデルを0から作る変な人からのお話ですが最急勾配法という誤差関数の最も下がる方向へ更新するという単純な実装から、このAdamという勾配を加速度的な手法(モーメンタム手法)で更新する実装に変えただけでモデルの収束が劇的によくなったという話があります。特に何もなければこれを使いましょう。  
ちなみにAdamの自力実装自体は簡単ですが何故その式で上手くいくのか？という問いにはまだ答えられるほどの数学力を持ち合わせていません。何でうまくいくんだろうね。  
```python
num_epochs = 5  # 学習回数
for epoch in range(num_epochs):
    running_loss = 0.0
    for images, labels in trainloader:
        images, labels = images.to(device), labels.to(device)  # GPUへ転送
        optimizer.zero_grad()  # 勾配の初期化
        outputs = model(images)  # 順伝播
        loss = criterion(outputs, labels)  # 損失計算
        loss.backward()  # 逆伝播
        optimizer.step()  # パラメータ更新
        running_loss += loss.item()
    print(f"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}")
```
これは学習をする部分です。学習一回をEpoch(エポック)という単位で表し、訓練データを全て使っています。
なのでここでは訓練データを全て使った更新を5回行っています。  
shuffle = Trueなので学習1回ごとに訓練データの順番がシャッフルされ順番による偏りを防ぐ。  
batch_size = 64なので
```python
for images, labels in trainloader:
```
で64個の入力データimagesと教師データlabelsが渡される。そして勾配の計算は64個のデータによる勾配の平均が使われる。  

```python
outputs = model(images) # 順伝播
```
で順伝播、つまりニューラルネットワークに入力データを入れ、入力層→隠れ層→出力層の方向で予測の計算をしている。  
outputsにはその結果、各ラベル(0~9)のlogitsスコアがミニバッチの個数(64個)格納されている。
```python
loss = criterion(outputs, labels)  # 損失計算
```
ここで入力データに対する予測のoutputsと教師データlabelsを比較するため誤差関数を計算している。  
今回は分類問題なので交差エントロピー誤差を使って評価する。  
```python
loss.backward()  # 逆伝播
```
予測データと教師データの誤差を計算したのでそこからモデルのパラメータを更新したい。  
そのために勾配を計算する必要があるのだがそれには各パラメータに対する偏微分が必要になる。  
それを行うために逆誤差伝播法と呼ばれる計算が必要でそれに対応するのが逆伝播の計算である。
その名の通り、出力層→隠れ層→入力層という順伝播とは逆の方向の計算をする。  
しかしうれしいことにライブラリを使えば順伝播の計算を定義すれば(forward関数や誤差関数に該当)逆伝播の計算を児童でやってくれる。  
AIモデルを0から作る変な人の場合、逆伝播すら自力で実装する必要があり地獄である(あった)。是非、これを読んでいる人にはこの一行で逆伝播の計算ができるライブラリの力に感動して欲しい。  
```python
optimizer.step()  # パラメータ更新
```
逆伝播の計算から勾配が求まったためその勾配を用いてパラメータの更新、つまりはモデルの学習を行う。  
まえにoptimizerとして定義したAdamはここで使われる。  
```python
running_loss += loss.item()
```
学習には直接関係がないが、学習の評価として人間が確認する用に誤差の合計をしている。  
Epochが進むたびに学習の誤差が減少していれば順調に学習が進んでいると分かる。  
もしこの誤差が逆に増加したり減少スピードが遅ければどこかに問題があるということになり脳がざわつくし心臓にも悪い。　　

## モデルの評価
```python
model.eval()  # 評価モード
```
これでモデルを評価モードに切り替えています。逆に
```python
model.train()  # 訓練モード
```
これでモデルを訓練モードに切り替えられます。
学習の際にはモデル内でドロップアウトやバッチ正規化等の学習するときの工夫の処理をすることがありこれをするかどうかを切り替えているようです。これらは評価の時には必要ないためにこの処理があります。  
```python
with torch.no_grad():
    for images, labels in testloader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
```
ここではモデルの評価を行っています。
```python
with torch.no_grad():
```
では勾配計算を無効化しています。この中にあるtorch.maxは予測スコアの最大値、つまり予測ラベルを返す処理があるのですがこの処理は学習とは関係なく、勾配の計算が不必要なのでこの記述が必要です。  
逆伝播の処理で自動微分を用いている関係でtorchの算術計算全てに偏微分の計算の処理が入ります。学習に関係なくただ処理をしたいときにはこのように勾配計算を無効化しましょう。

## 予測の可視化
```python
print('Predicted:', predicted)
imshow(torchvision.utils.make_grid(images.cpu()))
```
最後のこの行でmatplotによる画像の可視化(imshowは自作関数)、そして今回学習したモデルによる予測がコマンドプロンプトに表示されます。Predictedに表示された、実際に予測した数とmatplotで表示された画像を見比べて判定ができていることを確認してください。