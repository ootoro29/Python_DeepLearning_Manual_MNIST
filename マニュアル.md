# Python 環境での深層学習プログラムの作成マニュアル

## 1. 必要なライブラリのインストール

まず、Python環境があることを前提に、必要なライブラリを `pip` でインストールします。

```bash
pip install numpy pandas matplotlib torch torchvision
```

- `numpy` : 数値計算ライブラリ
- `pandas` : データ処理用ライブラリ
- `matplotlib` : グラフ描画ライブラリ
- `torch` : PyTorch の本体
- `torchvision` : 画像データの前処理やサンプルデータセットを扱うためのライブラリ

## 2. データの準備

今回は、`torchvision` に含まれる MNIST データセットを使用します。

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt

# データの前処理（正規化）
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# 訓練データとテストデータをダウンロード
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)

testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)
```

## 3. ニューラルネットワークの定義

簡単な全結合ニューラルネットワーク（MLP: Multi-Layer Perceptron）を作成します。

```python
class SimpleNN(nn.Module):
    def __init__(self):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(28 * 28, 128)  # 入力層（28x28ピクセル） → 隠れ層（128ユニット）
        self.fc2 = nn.Linear(128, 10)  # 隠れ層 → 出力層（10クラス：0~9）

    def forward(self, x):
        x = x.view(-1, 28 * 28)  # 画像を1次元のベクトルに変換
        x = torch.relu(self.fc1(x))  # 活性化関数ReLU適用
        x = self.fc2(x)  # 出力計算（Softmax適用は損失関数側で処理）
        return x
```

## 4. モデルの学習

学習ループを作成し、モデルを訓練します。

```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = SimpleNN().to(device)  # GPUが利用可能ならGPUへ転送

criterion = nn.CrossEntropyLoss()  # 損失関数（クロスエントロピー）
optimizer = optim.Adam(model.parameters(), lr=0.001)  # 最適化手法（Adam）

num_epochs = 5  # 学習回数
for epoch in range(num_epochs):
    running_loss = 0.0
    for images, labels in trainloader:
        images, labels = images.to(device), labels.to(device)  # GPUへ転送
        optimizer.zero_grad()  # 勾配の初期化
        outputs = model(images)  # 順伝播
        loss = criterion(outputs, labels)  # 損失計算
        loss.backward()  # 逆伝播
        optimizer.step()  # パラメータ更新
        running_loss += loss.item()
    print(f"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}")
```

## 5. モデルの評価

学習したモデルの精度をテストデータで確認します。

```python
correct = 0
total = 0
model.eval()  # 評価モード
with torch.no_grad():
    for images, labels in testloader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

accuracy = 100 * correct / total
print(f"Accuracy: {accuracy:.2f}%")
```

## 6. 予測の可視化

学習したモデルがどのように予測するかを確認します。

```python
import numpy as np

def imshow(img):
    img = img / 2 + 0.5  # 正規化を元に戻す
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')
    plt.show()

# サンプルデータの取得
images, labels = next(iter(testloader))
images, labels = images.to(device), labels.to(device)
outputs = model(images)
_, predicted = torch.max(outputs, 1)

# 画像と予測結果の表示
print('Predicted:', predicted)
imshow(torchvision.utils.make_grid(images.cpu()))
```

## 7. まとめ

以上の手順で、Python環境を準備し、深層学習を用いた手書き数字認識モデルを作成しました。

- `pip install` で必要なライブラリをインストール
- MNISTデータセットをダウンロードして前処理
- シンプルなMLPモデルを定義
- 損失関数と最適化手法を設定し、学習ループを実行
- テストデータで精度評価
- 予測結果を可視化

この手順を参考に、より高度な深層学習モデル（CNN, RNN, Transformer など）にも挑戦してみてください！

